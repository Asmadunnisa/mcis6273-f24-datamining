{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0add826e",
   "metadata": {},
   "source": [
    "<center>ASMADUNNISA BEGUM SHAIK<H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "161f40e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for winter 2008-2009 saved to data/winter_2008-2009.json\n",
      "Data for winter 2009-2010 saved to data/winter_2009-2010.json\n",
      "Data for winter 2010-2011 saved to data/winter_2010-2011.json\n",
      "Data for winter 2011-2012 saved to data/winter_2011-2012.json\n",
      "Data for winter 2012-2013 saved to data/winter_2012-2013.json\n",
      "Data for winter 2013-2014 saved to data/winter_2013-2014.json\n",
      "Data for winter 2014-2015 saved to data/winter_2014-2015.json\n",
      "Data for winter 2015-2016 saved to data/winter_2015-2016.json\n",
      "Data for winter 2016-2017 saved to data/winter_2016-2017.json\n",
      "Data for winter 2017-2018 saved to data/winter_2017-2018.json\n",
      "Data for winter 2018-2019 saved to data/winter_2018-2019.json\n",
      "Data for winter 2019-2020 saved to data/winter_2019-2020.json\n",
      "Data for winter 2020-2021 saved to data/winter_2020-2021.json\n",
      "Data for winter 2021-2022 saved to data/winter_2021-2022.json\n",
      "Average temperature: nan\n",
      "Average temperature of warmest days: 43.0968992248062\n",
      "Average temperature of coldest days: 17.160852713178294\n",
      "The 'date' column is not present in the DataFrame.\n",
      "No valid data for generating the heatmap.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Task 1: Fetch and store data\n",
    "def fetch_and_store_data(api_key, year_range):\n",
    "    base_url = \"https://www.ncei.noaa.gov/cdo-web/api/v2/data\"\n",
    "    dataset_id = \"GHCND\"\n",
    "    location_id = \"ZIP:80249\"\n",
    "    units = \"standard\"\n",
    "    limit = 1000\n",
    "\n",
    "    for year in range(year_range[0], year_range[1]):\n",
    "        start_date = f\"{year-1}-12-15\"\n",
    "        end_date = f\"{year}-01-21\"\n",
    "\n",
    "        params = {\n",
    "            'datasetid': dataset_id,\n",
    "            'locationid': location_id,\n",
    "            'units': units,\n",
    "            'startdate': start_date,\n",
    "            'enddate': end_date,\n",
    "            'limit': limit\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            'token': api_key\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            file_name = f'data/winter_{year}-{year+1}.json'\n",
    "\n",
    "            with open(file_name, 'w') as json_file:\n",
    "                json.dump(data, json_file)\n",
    "\n",
    "            print(f'Data for winter {year}-{year+1} saved to {file_name}')\n",
    "        except Exception as e:\n",
    "            print(f'Error fetching data for winter {year}-{year+1}: {str(e)}')\n",
    "\n",
    "# Task 2: Combine JSON files into CSV with TMAX, TMIN, and TAVG\n",
    "def combine_json_to_csv():\n",
    "    all_data = []\n",
    "    data_folder = 'data/'\n",
    "\n",
    "    for year in range(2008, 2022):\n",
    "        filename = f'{data_folder}winter_{year}-{year+1}.json'\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                all_data.extend(data['results'])\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['TMAX'] = df[df['datatype'] == 'TMAX']['value']\n",
    "    df['TMIN'] = df[df['datatype'] == 'TMIN']['value']\n",
    "    df['TAVG'] = (df['TMAX'] + df['TMIN']) / 2\n",
    "    df[['date', 'TMAX', 'TMIN', 'TAVG']].to_csv(data_folder + 'all_data_max_min_avg.csv', index=False)\n",
    "\n",
    "# Task 3: Compile data into CSV with TAVG for each date and year\n",
    "def compile_data_to_csv():\n",
    "    all_data = {}\n",
    "    data_folder = 'data/'\n",
    "\n",
    "    for year in range(2008, 2022):\n",
    "        filename = f'{data_folder}winter_{year}-{year+1}.json'\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                for entry in data['results']:\n",
    "                    date = pd.to_datetime(entry['date']).strftime('%m-%d')\n",
    "\n",
    "                    if date not in all_data:\n",
    "                        all_data[date] = {}\n",
    "\n",
    "                    all_data[date][f'{year}-{year+1}'] = entry['value']\n",
    "\n",
    "    df = pd.DataFrame.from_dict(all_data, orient='index')\n",
    "    df.sort_index(inplace=True)\n",
    "    df.to_csv(data_folder + 'all_data_min.csv')\n",
    "\n",
    "# Task 4: Functions to compute temperature averages\n",
    "def average(df):\n",
    "    return df['TAVG'].mean()\n",
    "\n",
    "def average_warmest(df):\n",
    "    return df['TMAX'].mean()\n",
    "\n",
    "def average_coldest(df):\n",
    "    return df['TMIN'].mean()\n",
    "\n",
    "\n",
    "# Task 5: Generate heatmap using Seaborn\n",
    "def generate_heatmap():\n",
    "    try:\n",
    "        df = pd.read_csv('data/all_data_max_min_avg.csv')\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['year'] = df['date'].dt.strftime('%Y')\n",
    "        df['day_month'] = df['date'].dt.strftime('%m-%d')\n",
    "        pivot_df = df.pivot_table(index='year', columns='day_month', values='TAVG', aggfunc='mean')\n",
    "        pivot_df = pivot_df.sort_index()\n",
    "\n",
    "        if not pivot_df.empty:\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            sns.heatmap(pivot_df, cmap='coolwarm', cbar_kws={'label': 'Average Temperature (Â°C)'})\n",
    "            plt.title('Average Temperature (TAVG) Heatmap (2008-2022)')\n",
    "            plt.xlabel('Day-Month')\n",
    "            plt.ylabel('Year')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No valid data for generating the heatmap.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating heatmap: {str(e)}\")\n",
    "\n",
    "def coldest_new_years_temp():\n",
    "    # Load the compiled CSV file\n",
    "    df = pd.read_csv('data/all_data_min.csv')\n",
    "    \n",
    "    # Ensure you have a column in your DataFrame that represents the date\n",
    "    # Adjust the column name accordingly\n",
    "    if 'date' in df.columns:\n",
    "        # Convert the date column to datetime\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Filter the data for 1/1\n",
    "        new_years_data = df[df['date'].dt.month == 1 & (df['date'].dt.day == 1)]\n",
    "        \n",
    "        if not new_years_data.empty:\n",
    "            # Find the coldest average temperature\n",
    "            coldest_avg_temp = new_years_data.min().min()\n",
    "            return coldest_avg_temp\n",
    "        else:\n",
    "            print(\"No data available for New Year's Day.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"The 'date' column is not present in the DataFrame.\")\n",
    "        return None\n",
    "\n",
    "# Main function to orchestrate the workflow\n",
    "def main():\n",
    "    api_key = 'onMnQMZLPZARhFhBZKtOJAKVOpNwjSWU'\n",
    "    year_range = (2008, 2022)\n",
    "\n",
    "    fetch_and_store_data(api_key, year_range)\n",
    "    combine_json_to_csv()\n",
    "    compile_data_to_csv()\n",
    "\n",
    "    all_data_max_min_avg = pd.read_csv('data/all_data_max_min_avg.csv')\n",
    "    print(\"Average temperature:\", average(all_data_max_min_avg))\n",
    "    print(\"Average temperature of warmest days:\", average_warmest(all_data_max_min_avg))\n",
    "    print(\"Average temperature of coldest days:\", average_coldest(all_data_max_min_avg))\n",
    "    coldest_temp = coldest_new_years_temp()\n",
    "    if coldest_temp is not None:\n",
    "        print(\"The coldest average New Year's Day temperature in all the data was:\", coldest_temp)\n",
    "\n",
    "    generate_heatmap()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9225f992",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26140/3626003225.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26140/3626003225.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'onMnQMZLPZARhFhBZKtOJAKVOpNwjSWU'\u001b[0m  \u001b[1;31m# Replace 'YOUR_API_KEY' with your actual NOAA API key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mprocess_weather_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mcombine_json_to_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mfilter_and_transform_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26140/3626003225.py\u001b[0m in \u001b[0;36mprocess_weather_data\u001b[1;34m(api_key)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mstart_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{year}-12-15'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mend_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{year+1}-01-21'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_weather_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'data/winter_{year}-{year+1}.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26140/3626003225.py\u001b[0m in \u001b[0;36mfetch_weather_data\u001b[1;34m(api_key, start_date, end_date)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'token'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{base_url}{endpoint}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Function to calculate TAVG from TMAX and TMIN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    908\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to make API call to NOAA and retrieve weather data\n",
    "def fetch_weather_data(api_key, start_date, end_date):\n",
    "    base_url = 'https://www.ncei.noaa.gov/data'\n",
    "    endpoint = '/daily-summaries'\n",
    "    params = {\n",
    "        'datasetid': 'GHCND',\n",
    "        'locationid': 'ZIP:80249',\n",
    "        'units': 'standard',\n",
    "        'startdate': start_date,\n",
    "        'enddate': end_date,\n",
    "        'limit': 1000\n",
    "    }\n",
    "    headers = {'token': api_key}\n",
    "    response = requests.get(f\"{base_url}{endpoint}\", params=params, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Function to calculate TAVG from TMAX and TMIN\n",
    "def calculate_tavg(tmax, tmin):\n",
    "    return (tmax + tmin) / 2\n",
    "\n",
    "# Function to process weather data and save it to JSON files\n",
    "def process_weather_data(api_key):\n",
    "    years = range(2008, 2023)  # Including 2022\n",
    "    for year in years:\n",
    "        start_date = f'{year}-12-15'\n",
    "        end_date = f'{year+1}-01-21'\n",
    "        data = fetch_weather_data(api_key, start_date, end_date)\n",
    "        with open(f'data/winter_{year}-{year+1}.json', 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "# Function to combine JSON files into a single CSV file with TMAX, TMIN, and TAVG\n",
    "def combine_json_to_csv():\n",
    "    data = []\n",
    "    for year in range(2008, 2023):\n",
    "        with open(f'data/winter_{year}-{year+1}.json', 'r') as f:\n",
    "            weather_data = json.load(f)\n",
    "            for entry in weather_data['results']:\n",
    "                date = entry['date']\n",
    "                tmax = entry.get('TMAX', None)\n",
    "                tmin = entry.get('TMIN', None)\n",
    "                tavg = calculate_tavg(tmax, tmin) if tmax is not None and tmin is not None else None\n",
    "                data.append({'Date': date, 'TMAX': tmax, 'TMIN': tmin, 'TAVG': tavg})\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('data/all_data_max_min_avg.csv', index=False)\n",
    "\n",
    "# Function to filter and transform CSV data\n",
    "def filter_and_transform_csv():\n",
    "    df = pd.read_csv('data/all_data_max_min_avg.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month_Day'] = df['Date'].dt.strftime('%m-%d')\n",
    "    df_pivot = df.pivot(index='Month_Day', columns='Year', values='TAVG')\n",
    "    df_pivot.to_csv('data/all_data_min.csv')\n",
    "\n",
    "# Function to compute average temperature from DataFrame\n",
    "def average(df):\n",
    "    return df.mean().mean()\n",
    "\n",
    "# Function to compute average of minimum temperature from DataFrame\n",
    "def average_warmest(df):\n",
    "    return df.min().mean()\n",
    "\n",
    "# Function to compute average of maximum temperature from DataFrame\n",
    "def average_coldest(df):\n",
    "    return df.max().mean()\n",
    "\n",
    "# Main function to execute the tasks\n",
    "def main():\n",
    "    api_key = 'onMnQMZLPZARhFhBZKtOJAKVOpNwjSWU'  # Replace 'YOUR_API_KEY' with your actual NOAA API key\n",
    "    process_weather_data(api_key)\n",
    "    combine_json_to_csv()\n",
    "    filter_and_transform_csv()\n",
    "    # Loading data for further analysis\n",
    "    df = pd.read_csv('data/all_data_min.csv', index_col='Month_Day')\n",
    "    # Computing temperature averages\n",
    "    avg_temp = average(df)\n",
    "    avg_warmest = average_warmest(df)\n",
    "    avg_coldest = average_coldest(df)\n",
    "    print(\"Average Temperature:\", avg_temp)\n",
    "    print(\"Average of Warmest Temperatures:\", avg_warmest)\n",
    "    print(\"Average of Coldest Temperatures:\", avg_coldest)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa763a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
